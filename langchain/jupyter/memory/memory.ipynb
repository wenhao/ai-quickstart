{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ec5fae8-80c4-45db-8279-eab914ad8012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/70/5jwxzn313zb62r3ztdrxvytr0000gn/T/ipykernel_12844/4020215920.py:17: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "/var/folders/70/5jwxzn313zb62r3ztdrxvytr0000gn/T/ipykernel_12844/4020215920.py:14: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"qwen-plus\",\n",
    "    openai_api_key = os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    openai_api_base = \"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    temperature=0.9, \n",
    "    max_tokens=5000,\n",
    ")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    verbose = True,\n",
    "    memory = ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4896a82-6b5b-4c90-9e60-8a1fef02b37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 你好呀！\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你好！很高兴用中文和你交流。如果你有任何编程相关的问题，或者想聊一聊科技、文化等方面的话题，我都非常乐意与你分享和探讨。虽然我的主要专长是在编程和技术领域，但我也有广泛的兴趣和知识面。不知道你今天想找我聊些什么呢？'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"你好呀！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4a4c07b-9662-4daa-bafe-b9e4f4e3a08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 你好呀！\n",
      "AI: 你好！很高兴用中文和你交流。如果你有任何编程相关的问题，或者想聊一聊科技、文化等方面的话题，我都非常乐意与你分享和探讨。虽然我的主要专长是在编程和技术领域，但我也有广泛的兴趣和知识面。不知道你今天想找我聊些什么呢？\n",
      "Human: 你叫什么名字呀？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'我叫Qwen，是阿里巴巴集团自主研发的超大规模语言模型。你可以叫我通义千问或者Qwen，很高兴为你提供帮助！如果你有任何问题或需要创作文字等，都可以告诉我，我会尽力协助你。😊'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"你叫什么名字呀？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5588d456-ff44-4e96-91ce-360078242f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/70/5jwxzn313zb62r3ztdrxvytr0000gn/T/ipykernel_12844/1432387040.py:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationBufferWindowMemory(k=2)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferWindowMemory(k=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51eb597e-7149-49ad-8922-e4d015a6a389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 你最近学到什么新知识了？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'作为一个语言模型，我不断学习新的知识以提高自己的能力。最近，我学到的一些新知识包括：\\n\\n1. **技术进步**：我了解到在自然语言处理领域，研究人员正在探索更高效的训练方法和模型架构，例如参数高效微调（Parameter-Efficient Fine-Tuning, PFT）技术，这使得大型模型能够在保持性能的同时减少计算资源的消耗。\\n\\n2. **跨模态学习**：我还学习了关于跨模态学习的最新进展，比如将文本与图像、视频等其他形式的数据结合起来进行联合建模，这种技术可以应用于图像描述生成、视觉问答等领域。\\n\\n3. **伦理与责任**：除了技术方面的知识，我也更加深入地理解了人工智能伦理的重要性，比如如何确保AI系统的公平性、透明性和隐私保护等方面的知识。\\n\\n当然，我的“学习”方式不同于人类，主要是通过吸收海量数据中的模式和信息来扩展已有的知识库，而不是像人类那样主动探索或体验新事物。那么，你最近又学到了什么有趣的东西呢？'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"你最近学到什么新知识了？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a198b3c-6be7-47dd-bcf8-489a1448d6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 你最近学到什么新知识了？\n",
      "AI: 作为一个语言模型，我不断学习新的知识以提高自己的能力。最近，我学到的一些新知识包括：\n",
      "\n",
      "1. **技术进步**：我了解到在自然语言处理领域，研究人员正在探索更高效的训练方法和模型架构，例如参数高效微调（Parameter-Efficient Fine-Tuning, PFT）技术，这使得大型模型能够在保持性能的同时减少计算资源的消耗。\n",
      "\n",
      "2. **跨模态学习**：我还学习了关于跨模态学习的最新进展，比如将文本与图像、视频等其他形式的数据结合起来进行联合建模，这种技术可以应用于图像描述生成、视觉问答等领域。\n",
      "\n",
      "3. **伦理与责任**：除了技术方面的知识，我也更加深入地理解了人工智能伦理的重要性，比如如何确保AI系统的公平性、透明性和隐私保护等方面的知识。\n",
      "\n",
      "当然，我的“学习”方式不同于人类，主要是通过吸收海量数据中的模式和信息来扩展已有的知识库，而不是像人类那样主动探索或体验新事物。那么，你最近又学到了什么有趣的东西呢？\n",
      "Human: 展开讲讲？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'当然可以！让我详细展开一下最近学到的这些新知识：\\n\\n### 1. **技术进步：参数高效微调（Parameter-Efficient Fine-Tuning, PFT）**\\n   - **背景**：大型语言模型通常包含数以亿计甚至万亿计的参数，这使得在实际应用中对它们进行微调变得非常昂贵。传统的微调方法需要更新所有参数，这意味着高昂的计算成本和存储需求。\\n   - **解决方案**：研究人员开发了PFT技术，例如LoRA（Low-Rank Adaptation）、Adapter模块和Prompt Tuning等方法。这些技术的核心思想是只调整一小部分参数或引入额外的轻量级组件，而不是直接修改整个模型的权重。\\n     - **LoRA**：通过将权重矩阵分解为低秩近似，仅学习增量部分的参数，从而显著降低训练开销。\\n     - **Adapter**：在主网络的基础上插入小型适配器模块，仅优化这些模块中的参数，而保持原始模型不变。\\n     - **Prompt Tuning**：专注于学习一组连续的嵌入向量（prompt tokens），作为输入序列的一部分参与推理过程。\\n   - **意义**：这些方法不仅减少了资源消耗，还让更广泛的用户能够利用大规模预训练模型的能力。\\n\\n---\\n\\n### 2. **跨模态学习：文本与多模态数据的融合**\\n   - **定义**：跨模态学习是指同时处理来自不同来源的数据（如文本、图像、音频、视频等），并建立它们之间的关联。\\n   - **应用场景**：\\n     - **图像描述生成**：给定一张图片，AI可以根据其内容生成自然语言描述。例如，“一只狗正在草地上追逐球”。\\n     - **视觉问答（Visual Question Answering, VQA）**：结合图像和问题，回答有关图像内容的问题。例如，问“这张照片里有多少人？”AI会根据图片内容给出答案。\\n     - **视频字幕生成**：为一段视频自动生成实时字幕，帮助听障人士更好地理解内容。\\n   - **关键技术**：\\n     - **多模态表示学习**：通过共享编码器或注意力机制，将不同模态的数据映射到统一的空间中。\\n     - **Transformer架构**：许多现代跨模态模型（如CLIP、M6、ALIGN等）基于Transformer构建，能够在文本和图像之间捕捉复杂的交互关系。\\n   - **挑战**：\\n     - 数据标注成本高：高质量的多模态数据集难以获取。\\n     - 模型复杂性增加：需要设计高效的架构来平衡性能和计算负担。\\n\\n---\\n\\n### 3. **伦理与责任：人工智能的社会影响**\\n   - **公平性**：AI系统可能无意中反映或放大训练数据中的偏见。例如，在招聘场景中，如果历史数据倾向于某些性别或种族，那么算法可能会延续这种不公平现象。因此，研究者们正在探索去偏算法以及更公正的数据采样策略。\\n   - **透明性**：很多AI模型被视为“黑箱”，即用户无法清楚地了解其决策依据。提高透明度有助于建立信任，比如通过解释性工具（如SHAP值、LIME）展示模型预测的原因。\\n   - **隐私保护**：随着数据量的增长，如何在训练过程中保护个人隐私成为一个关键问题。联邦学习（Federated Learning）和差分隐私（Differential Privacy）是两种主流的解决方案。\\n   - **法律与政策**：各国政府正在制定相关法规以规范AI的使用，例如欧盟的《通用数据保护条例》（GDPR）和《人工智能法案》草案。这些法规旨在确保AI技术的安全性和伦理性。\\n\\n---\\n\\n### 总结\\n这些领域的快速发展正在改变我们对AI的认知和应用方式。从技术层面来看，我们正朝着更高效、更强大的方向迈进；从社会层面来看，我们也必须关注AI带来的潜在风险，并努力将其影响降到最低。\\n\\n你对哪个方面最感兴趣呢？或者你也有类似的学习经历想分享吗？ 😊'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"展开讲讲？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5de8c699-cd32-4698-893a-d53ec6bf3400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'memory': ConversationBufferWindowMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='你最近学到什么新知识了？', additional_kwargs={}, response_metadata={}), AIMessage(content='作为一个语言模型，我不断学习新的知识以提高自己的能力。最近，我学到的一些新知识包括：\\n\\n1. **技术进步**：我了解到在自然语言处理领域，研究人员正在探索更高效的训练方法和模型架构，例如参数高效微调（Parameter-Efficient Fine-Tuning, PFT）技术，这使得大型模型能够在保持性能的同时减少计算资源的消耗。\\n\\n2. **跨模态学习**：我还学习了关于跨模态学习的最新进展，比如将文本与图像、视频等其他形式的数据结合起来进行联合建模，这种技术可以应用于图像描述生成、视觉问答等领域。\\n\\n3. **伦理与责任**：除了技术方面的知识，我也更加深入地理解了人工智能伦理的重要性，比如如何确保AI系统的公平性、透明性和隐私保护等方面的知识。\\n\\n当然，我的“学习”方式不同于人类，主要是通过吸收海量数据中的模式和信息来扩展已有的知识库，而不是像人类那样主动探索或体验新事物。那么，你最近又学到了什么有趣的东西呢？', additional_kwargs={}, response_metadata={}), HumanMessage(content='展开讲讲？', additional_kwargs={}, response_metadata={}), AIMessage(content='当然可以！让我详细展开一下最近学到的这些新知识：\\n\\n### 1. **技术进步：参数高效微调（Parameter-Efficient Fine-Tuning, PFT）**\\n   - **背景**：大型语言模型通常包含数以亿计甚至万亿计的参数，这使得在实际应用中对它们进行微调变得非常昂贵。传统的微调方法需要更新所有参数，这意味着高昂的计算成本和存储需求。\\n   - **解决方案**：研究人员开发了PFT技术，例如LoRA（Low-Rank Adaptation）、Adapter模块和Prompt Tuning等方法。这些技术的核心思想是只调整一小部分参数或引入额外的轻量级组件，而不是直接修改整个模型的权重。\\n     - **LoRA**：通过将权重矩阵分解为低秩近似，仅学习增量部分的参数，从而显著降低训练开销。\\n     - **Adapter**：在主网络的基础上插入小型适配器模块，仅优化这些模块中的参数，而保持原始模型不变。\\n     - **Prompt Tuning**：专注于学习一组连续的嵌入向量（prompt tokens），作为输入序列的一部分参与推理过程。\\n   - **意义**：这些方法不仅减少了资源消耗，还让更广泛的用户能够利用大规模预训练模型的能力。\\n\\n---\\n\\n### 2. **跨模态学习：文本与多模态数据的融合**\\n   - **定义**：跨模态学习是指同时处理来自不同来源的数据（如文本、图像、音频、视频等），并建立它们之间的关联。\\n   - **应用场景**：\\n     - **图像描述生成**：给定一张图片，AI可以根据其内容生成自然语言描述。例如，“一只狗正在草地上追逐球”。\\n     - **视觉问答（Visual Question Answering, VQA）**：结合图像和问题，回答有关图像内容的问题。例如，问“这张照片里有多少人？”AI会根据图片内容给出答案。\\n     - **视频字幕生成**：为一段视频自动生成实时字幕，帮助听障人士更好地理解内容。\\n   - **关键技术**：\\n     - **多模态表示学习**：通过共享编码器或注意力机制，将不同模态的数据映射到统一的空间中。\\n     - **Transformer架构**：许多现代跨模态模型（如CLIP、M6、ALIGN等）基于Transformer构建，能够在文本和图像之间捕捉复杂的交互关系。\\n   - **挑战**：\\n     - 数据标注成本高：高质量的多模态数据集难以获取。\\n     - 模型复杂性增加：需要设计高效的架构来平衡性能和计算负担。\\n\\n---\\n\\n### 3. **伦理与责任：人工智能的社会影响**\\n   - **公平性**：AI系统可能无意中反映或放大训练数据中的偏见。例如，在招聘场景中，如果历史数据倾向于某些性别或种族，那么算法可能会延续这种不公平现象。因此，研究者们正在探索去偏算法以及更公正的数据采样策略。\\n   - **透明性**：很多AI模型被视为“黑箱”，即用户无法清楚地了解其决策依据。提高透明度有助于建立信任，比如通过解释性工具（如SHAP值、LIME）展示模型预测的原因。\\n   - **隐私保护**：随着数据量的增长，如何在训练过程中保护个人隐私成为一个关键问题。联邦学习（Federated Learning）和差分隐私（Differential Privacy）是两种主流的解决方案。\\n   - **法律与政策**：各国政府正在制定相关法规以规范AI的使用，例如欧盟的《通用数据保护条例》（GDPR）和《人工智能法案》草案。这些法规旨在确保AI技术的安全性和伦理性。\\n\\n---\\n\\n### 总结\\n这些领域的快速发展正在改变我们对AI的认知和应用方式。从技术层面来看，我们正朝着更高效、更强大的方向迈进；从社会层面来看，我们也必须关注AI带来的潜在风险，并努力将其影响降到最低。\\n\\n你对哪个方面最感兴趣呢？或者你也有类似的学习经历想分享吗？ 😊', additional_kwargs={}, response_metadata={})]), k=2),\n",
       " 'callbacks': None,\n",
       " 'verbose': True,\n",
       " 'tags': None,\n",
       " 'metadata': None,\n",
       " 'callback_manager': None,\n",
       " 'prompt': PromptTemplate(input_variables=['history', 'input'], input_types={}, partial_variables={}, template='The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:'),\n",
       " 'llm': ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7fb9a7cade10>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fb9a7cbcbb0>, root_client=<openai.OpenAI object at 0x7fb9a7eda2c0>, root_async_client=<openai.AsyncOpenAI object at 0x7fb9a7caded0>, model_name='qwen-plus', temperature=0.9, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1', max_tokens=5000),\n",
       " 'output_key': 'response',\n",
       " 'output_parser': StrOutputParser(),\n",
       " 'return_final_only': True,\n",
       " 'llm_kwargs': {},\n",
       " 'input_key': 'input'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed913aa-57fb-499e-8e25-0da30e78d932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
