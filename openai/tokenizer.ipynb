{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d02ddde8-c994-46b7-a454-d723fcba2bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dashscope import get_tokenizer\n",
    "\n",
    "def get_tokens(model, message):\n",
    "    tokenizer = get_tokenizer(model)\n",
    "    tokens = tokenizer.encode(message)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6cb14fd-6756-443e-abbb-e31acef81e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过切分后的token id为：[31935, 64559, 99320, 56007, 100629, 104795, 99788, 1773]。\n",
      "经过切分后共有8个token\n",
      "token id为31935对应的字符串为：通\n",
      "token id为64559对应的字符串为：义\n",
      "token id为99320对应的字符串为：千\n",
      "token id为56007对应的字符串为：问\n",
      "token id为100629对应的字符串为：具有\n",
      "token id为104795对应的字符串为：强大的\n",
      "token id为99788对应的字符串为：能力\n",
      "token id为1773对应的字符串为：。\n"
     ]
    }
   ],
   "source": [
    "model='qwen-plus'\n",
    "message='通义千问具有强大的能力。'\n",
    "tokens = get_tokens(model, message)\n",
    "\n",
    "print(f\"经过切分后的token id为：{tokens}。\")\n",
    "print(f\"经过切分后共有{len(tokens)}个token\")\n",
    "\n",
    "for i in range(len(tokens)):\n",
    "    print(f\"token id为{tokens[i]}对应的字符串为：{tokenizer.decode(tokens[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d26619e-4052-49d4-921b-943d873556a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过切分后的token id为：[33035, 65659, 11239, 225, 57107, 77913, 19361, 13870, 118, 27384, 9554, 27327, 48634, 1811]。\n",
      "经过切分后共有14个token\n",
      "token id为33035对应的字符串为：checkout\n",
      "token id为65659对应的字符串为：/car\n",
      "token id为11239对应的字符串为：tle\n",
      "token id为225对应的字符串为：�\n",
      "token id为57107对应的字符串为： Supervisor\n",
      "token id为77913对应的字符串为： ISR\n",
      "token id为19361对应的字符串为： Manchester\n",
      "token id为13870对应的字符串为： tack\n",
      "token id为118对应的字符串为：�\n",
      "token id为27384对应的字符串为：.jupiter\n",
      "token id为9554对应的字符串为：.getInstance\n",
      "token id为27327对应的字符串为：.parameters\n",
      "token id为48634对应的字符串为：=D\n",
      "token id为1811对应的字符串为：rows\n",
      "原文还原：checkout/cartle� Supervisor ISR Manchester tack�.jupiter.getInstance.parameters=Drows\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding('cl100k_base')\n",
    "message='通义千问具有强大的能力。'\n",
    "tokens = encoding.encode(message)\n",
    "print(f\"经过切分后的token id为：{tokens}。\")\n",
    "print(f\"经过切分后共有{len(tokens)}个token\")\n",
    "for i in range(len(tokens)):\n",
    "    print(f\"token id为{tokens[i]}对应的字符串为：{tokenizer.decode(tokens[i])}\")\n",
    "\n",
    "print(f\"原文还原：{tokenizer.decode(tokens)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9da447b-a69a-4809-8ae2-64cb68cff873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 20:21:55,418 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /Users/wenhao/.cache/modelscope/hub/models/Qwen/QwQ-32B\n",
      "经过切分后的token id为：[31935, 64559, 99320, 56007, 100629, 104795, 99788, 1773]。\n",
      "经过切分后共有8个token\n",
      "token id为31935对应的字符串为：通\n",
      "token id为64559对应的字符串为：义\n",
      "token id为99320对应的字符串为：千\n",
      "token id为56007对应的字符串为：问\n",
      "token id为100629对应的字符串为：具有\n",
      "token id为104795对应的字符串为：强大的\n",
      "token id为99788对应的字符串为：能力\n",
      "token id为1773对应的字符串为：。\n"
     ]
    }
   ],
   "source": [
    "from modelscope import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/QwQ-32B\")\n",
    "message = '通义千问具有强大的能力。'\n",
    "tokens = tokenizer.encode(message)\n",
    "\n",
    "print(f\"经过切分后的token id为：{tokens}。\")\n",
    "print(f\"经过切分后共有{len(tokens)}个token\")\n",
    "\n",
    "for i in range(len(tokens)):\n",
    "    print(f\"token id为{tokens[i]}对应的字符串为：{tokenizer.decode(tokens[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d0b693-fd05-4201-a32f-3c9ccfd56b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
